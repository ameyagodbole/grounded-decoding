program: scripts/summarization/run_headmask.py
name: xsum-llama2-chat-cad_head_mask-v2
method: grid
parameters:
  cad_alpha:
    values: [4.0, 2.0, 1.5, 1.0, 0.5, 0.25]
  mask_topk:
    values: [10, 20, 50, 100, 150]
command:
- "python"
- ${program}
- ${args}
- "--model_nm"
- "llama2-chat"
- "--dataset_nm"
- "xsum"
- "--decoding_algo"
- "cad_head_mask"
- "--generation_config"
- "configs/topp_config.json"
- "--output_dir"
- "/home/ameya/grounded-decoding/outputs/xsum/"
- "--cad_kv_sharing"
- "total"
- "--head_score_file"
- "configs/retrieval_head_score/llama-2-7b-80k.json"
- "--return_js_divergence"
- "--n_samples"
- "250"
- "--shuffle_seed"
- "1904"
- "--topp"
- "0.9"
- "--temperature"
- "1.0"
- "--log_wandb"